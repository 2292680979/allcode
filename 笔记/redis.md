1. 链接：https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247484609&idx=1&sn=4c053236699fde3c2db1241ab497487b&chksm=ebd745c0dca0ccd682e91938fc30fa947df1385b06d6ae9bb52514967b0736c66684db2f1ac9###rd

2. redis：Redis是基于内存，常用作于缓存的一种技术，并且Redis存储的方式是以key-value的形式。

3. 为什么要用缓存：1.高性能，缓存查询速度比数据库查询速度快。2.高并发：缓存分担了部分请求，这样用户的一部分请求会直接到缓存这里而不用经过数据库，支持更快的并发。

4. Redis的键值对：key一定是字符串，value任意（String，list，hash，set，sorted set/zset）。对象系统：key与value并不是直接使用string，list等几种数据类型，而是基于这些数据类型创建了一个对象系统（redisObject），对象包括：实际的对象类型（5种），对象编码格式（7种如ziplist等），指针等。

5. Redis底层数据结构：

   > 1. SDS（Simple Dynamic String）：简单动态字符串，一个名为sdshdr的结构体，包含三个参数（buf：char数组，len：buf的长度，free：buf的剩余长度），这样设计的好处：a.可以直接获取字符串长度  b.减少内存再分配，因为有free，所以可以直接加到后面的free，而不用每次改变string都分配内存  c.c语言中字符串是以'\0'作为结束符，而buf因为是根据长度取值，所以不用判断'\0'，所以可以存储除字符串外的其他类型而没有歧义。（二进制安全）
   > 2. 双向链表（list，listNode）：list中记录了listNode类型的头节点，尾节点，链表长度，listNode中记录了value，pre，next。其中value使用void *类型，可以保存各种不同类型的值。
   > 3. 字典（dict，dictht，dictEntry）：dictht结构体包含dictEntry类型的哈希数组，哈希表大小，已有节点数量，计算索引的掩码。dictEntry包含了void *类型的key与可以为void *类型或者int类型的value，和同为dictEntry的next，形成链表（与hashmap类型）。dict包含类型特定函数的结构体，长度为2的dictht哈希表数组ht[2]，一般来说我们用0位置上的哈希表，当扩容发生的时候，1位置才会被使用。   rehash步骤：1. 根据ht[0]的数据选择扩大或者缩小，分配ht[1]的大小  2.将ht[0]数据rehash到ht[1]上 3.完成后，将ht[1]设置为ht[0]，生成一个新的ht[1].      渐进式rehash（数据太多时普通rehash太慢，渐进式rehash使得redis在rehash时也能继续提供服务）：1. rehash开始时设置字典中的rehashidx为0  2.rehash时增删改查除了执行原来的操作，还会将ht[0]中rehashidx索引上的值rehash到ht[1]，然后rehashidx+1  3.一段时间后，所有的键值对完成rehash，将rehashidx设置为-1，表示rehash完成。另外：在进行 rehash 的过程中，如果进行了 delete 和 update 等操作，会在两个哈希表上进行。如果是 find 的话优先在ht[0] 上进行，如果没有找到，再去 ht[1] 中查找。如果是 insert 的话那就只会在 ht[1]中插入数据。这样就会保证了 ht[1] 的数据只增不减，ht[0]的数据只减不增
   > 4. 跳表详解（https://www.jianshu.com/p/9d8296562806）：通过增加多级索引，使得链表查找时间符合二分查找（logn），空间复杂度为n（n/2+n/4+n/8+...+2+1），因为索引只需要存储key与几个指针，所以当数据列很多时，占用的空间可以忽略（如每一个链表节点需要存储十几个属性）。插入：原始链表是有序的，首先需要查找到正确位置，然后插入，还需要维护索引。选取索引时，我们可以随机选取n/2个元素，而不是严格按照固定的间隔，每次插入元素时，尽量让该元素有 1/2 的几率建立一级索引、1/4 的几率建立二级索引、1/8 的几率建立三级索引等等（随机算法），插入时，用此算法决定此元素要加入几级索引，这样就不用花大量时间维护所有索引了，只需要决定此索引的插入位置。 删除：查找到需要删除的值，然后删除，时间复杂度logn。  **为什么redis中用跳表而不是红黑树呢**？增删改查两者时间相似，但是在实现按范围输出元素时，跳表只需要查找到起始元素然后往后遍历即可，而红黑树更复杂。
   > 5. 跳表（实现zset）（zskiplist，zskiplistNode）：zskiplist保存了表头表尾节点，长度，层数。zskiplistNode则保存了double类型的score值，member域指针作为元素，使用score值进行排序，还存储了后向指针，当前层下一个节点的指针，到达下一个节点经过的节点跨度。
   > 6. 整数集合（intset）：实现set的底层数据结构之一，当一个set(集合)只包含整数值元素，并且元素的数量不多时，Redis就会采用整数集合(intset)作为set(集合)的底层实现。intset包含了编码方式，元素个数，保存元素的数组。存放数据的大小范围由编码方式决定，有16位/32位/64位，只支持升级，不支持降级。
   > 7. 压缩列表（ziplist）：压缩列表是list和hash的底层实现之一。如果list的每个都是小整数值，或者是比较短的字符串，压缩列表(ziplist)作为list的底层实现，压缩列表(ziplist)是Redis为了节约内存而开发的，是由一系列的特殊编码的连续内存块组成的顺序性数据结构。压缩列表从表尾倒序遍历，首先s指针通过zltail偏移量指向表尾节点，然后通过指向节点记录的前一个节点的长度（每个节点都记录了前一个节点的长度，编码，内容）依次向前遍历访问整个压缩列表。

6. Redis中的数据库：redis默认有16个数据库，数据库之间是相互隔离的。底层结构：**1个server包括一个大小为16的db数组**，1个client指向当前正在使用的db，每个db包含**两个哈希表**，一个哈希表包含此数据库所有key-value，一个包含所有key的过期时间

7. （重点）过期策略（key到了过期时间会立马删除掉吗？）：定时删除(对内存友好，对CPU不友好)：到时间点上就把所有过期的键删除了。惰性删除(对CPU极度友好，对内存极度不友好)：每次从键空间取键的时候，判断一下该键是否过期了，如果过期了就删除。定期删除(折中)：每隔一段时间去删除过期键，限制删除的执行时长和频率。   Redis采用的是惰性删除+定期删除两种策略，所以说，在Redis里边如果过期键到了过期的时间了，未必被立马删除的。  

8. （重点）如何**判断一个键是否过期**呢？首先检查数据库中的过期时间哈希表，如果没在里面说明不会过期，如果存在就获取过期时间，检查当前的时间是否大于过期时间，是则过期。  **定期删除原理**：从数据库中的过期时间哈希表中随机选取20个键，删除其中过期的键，如果过期的键比例超过25%则重复上几步，扫描时间上限默认25毫秒。

9. （重点）内存淘汰策略（如果定期删除漏掉了很多过期key，也没及时去查(没走惰性删除)，大量过期key堆积在内存里，导致redis内存块耗尽了（可以设置内存最大使用量），咋整？）：allkeys-lru：从所有数据集中挑选**最近最少**使用的数据淘汰。volatile-lru 设置了过期时间的key参与近似的lru淘汰策略（即随机选取一定的值，并从中进行淘汰，而不是所有数据集）。

10. Lru实现原理（https://zhuanlan.zhihu.com/p/34133067）：可以用双向链表和hashmap实现。Key存储在hashmap中，使得get(key)和save时间复杂度都是1，hashmap的value指向双向链表某个节点，双向链表中存储了key对应的value。1.Save时，首先判断hashmap中是否存在key，如果节点存在，更新节点的值，并把这个节点移动队头。如果不存在，需要构造新的节点，并且尝试把节点塞到队头，如果LRU空间不足，则通过 tail 淘汰掉队尾的节点，同时在 HashMap 中移除 Key。2.get时，通过hashmap定位此节点在链表中的位置，然后把此节点插入表头，并返回数据。

11. Redis会随机选取固定数目的key，然后比较他们的lru访问时间（在server中提供了一个全局lrulock供每个object更新自己的时钟，sever每100ms更新一次lrulock，每个object初始化/更新的时候会从lrulock中得到现在的时钟），然后淘汰最近最少使用的key，固定值可以改变，值越大，消耗越高，volatile就越接近allkeys，默认为15.

12. Redis持久化（因为redis是基于内存的，所以重启后数据会全部丢失，所以需要我们把数据写入到磁盘中便于恢复）：1. RDB(基于快照)，将某一时刻的所有数据保存到一个RDB文件中。  2. AOF(append-only-file)，当Redis服务器执行写命令的时候，将执行的写命令保存到AOF文件中。

13. RDB（默认持久化方式）:可以手动（SAVE）/定期（BGSAVE）执行持久化，RDB文件是一个经过压缩的二进制文件，redis启动时，如果发现有RDB文件，就会自动载入RDB文件，服务器在载入RDB文件期间，会处于阻塞状态。生成RDB文件的命令：SAVE:阻塞redis服务器进程。BGSAVE:由子进程生成RDB文件，服务器进程继续接受请求。  默认：（save 900 1）在900秒(15分钟)之后，至少有1个key发生变化等，就会执行BGSAVE命令 （save 300 10）（save 60 10000）（三个条件触发一条，就会BGSAVE）

14. AOF：redis执行了一个写命令后（如set），以协议格式将被执行的命令追加到aof_buf缓冲区的末尾，随后调用flushAppendOnlyFile()函数考虑是否将缓冲区的内容写入到AOF文件（操作系统的内存缓冲区），最后确定是否将AOF文件同步（即写入磁盘）   faof函数：由三种写入文件选项：1.有数据修改就写入 2.默认，每秒同步一次 3.从不同步

15. AOF文件载入：创建一个伪客户端，不断从aof文件中读取写命令并执行。  AOF重写：**可以让aof文件体积变小**（比如多条set语句可以合成一条），BGREWRITEAOF命令，aof重写不用读取原来的aof文件，而是通过**读取数据库**生成命令并用生成的新的aof文件**替换旧的**。解决重写导致aof与数据库不一致：创建的**子进程**执行重写操作，还没有重写完时，客户端发起的写操作会到aof缓冲区中，子进程完成重写后，把缓冲区中的数据写入aof文件。

16. 过期策略：RDB：创建RDB文件时，程序会对数据库中的所有键值进行过期检查，过期的键值不写入文件，载入文件时过期的不会被载入。 AOF：如果过期的键还没被删除，AOF也会写入，当过期的键被删除后（惰性删除或定期删除），会**追加一条del**命令显示该键被删除，重写aof文件时，过期的键会被忽略。 复制模式：主服务器来控制从服务器统一删除过期键(保证主从服务器数据的一致性)，主服务器删除后，根据命令传播，从服务器也会删除，主服务器没删除，从服务器遇到客户端访问过期键任然会把过期键发送给客户端。

17. 优缺点：RDB：优：载入时恢复数据快、文件体积小。缺：会一定程度上丢失数据(因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。) AOF：优：丢失数据少(默认配置只丢失一秒的数据)。缺：恢复数据相对较慢，文件体积大   如果redis同时开启两者，服务器优先使用aof还原数据，因为aof丢失数据少。服务器可以同时使用两者。

18. Redis事件：文件事件：客户端与服务器网络通信，时间事件：一些定时操作

19. 文件事件：I/O多路复用程序会同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生，将所有产生事件的Socket放到一个队列，然后每次处理一个，依次有序向文件事件分派器传送套接字，当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕）， I/O 多路复用程序才会继续向文件事件分派器传送下一个套接字。

20. 时间事件：Redis服务器将时间事件放在一个链表中，当时间事件执行器运行时，会遍历整个链表。其中，时间事件包括周期性事件（serverCron函数，包括持久化，清理过期键等）与定时事件

21. 1. 文件事件和时间事件之间是合作关系，服务器会轮流处理这两种事件，并且处理事件的过程中不会发生抢占。2. 时间事件的实际处理事件通常会比设定的到达时间晚一些

22. Redis为什么这么快？1. 纯内存操作  2. 核心是基于非阻塞的IO多路复用机制  3. 单线程避免了多线程的频繁上下文切换问题

23. Redis单线程不是浪费cpu吗？因为单线程已经够用了，CPU不是redis的瓶颈。Redis的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。

24. 一个服务器可以与多个客户端建立网络连接（服务器使用链表连接多个客户端状态）。Redis服务器使用单线程单进程的方式处理命令请求。客户端与服务器交流过程：客户端将命令请求发送给服务器，服务器读取命令请求，分析出命令参数，命令执行器根据参数查找命令的实现函数，执行实现函数并得出命令回复，服务器将命令回复返回给客户端。

25. 为什么使用服务器主从架构：1.单台服务器内存有限 2.单台服务器支持并发量也有限 3.万一redis服务器挂了，所有请求全走关系数据库了，那就更炸了。（高可用，高并发）  

26. 服务器主从架构是：一台主服务器，多台从服务器。主服务器负责接收写请求。从服务器负责接收读请求。从服务器的数据由主服务器复制过去，主从服务器的数据是一致的。

27. 复制功能：同步（初次同步，断线同步），命令传播（主服务器的写命令也给从服务器执行）

28. 复制的前置工作：主服务向从服务器发送SAVLEOF命令，从服务器收到命令后，记录下主服务器的ip和端口，并与主服务器建立socket，并为该socket绑定文件处理器，建立socket后，从服务器给主服务器发送ping命令，并进行身份认证

29. 完整重同步（初次同步）：从服务器向主服务器发送PSYNC命令，收到PSYNC命令的主服务器执行BGSAVE命令，在后台生成一个**RDB文件**。并用一个缓冲区来记录从现在开始执行的所有写命令。当主服务器的BGSAVE命令执行完后，将生成的RDB文件发送给从服务器，从服务器接收和载入RBD文件。将自己的数据库状态更新至与主服务器执行BGSAVE命令时的状态。主服务器将所有**缓冲区的写命令发送给从服务器**，从服务器执行这些写命令，达到数据最终一致性。

30. 部分重同步（断线同步）：从服务器接受到主服务器发送的SAVLEOF命令，判断是否是第一次执行复制，是则执行完整重同步，不是则向主服务器发送服务器的**运行id和偏移量**，主服务器判断运行id是否相同，**复制积压缓冲区是否存在丢失的偏移量的数据**，如果是，则部分重同步（即从复制积压缓冲区中将偏移量相差的部分发送给从服务器）。 偏移量：主服务器每次**传播N个字节**，就将自己的复制偏移量加上N，从服务器每次收到主服务器的N个字节，就将自己的复制偏移量加上N  复制积压缓冲区：当主服务器进行命令传播时，不仅仅会将**写命令**发送给所有的从服务器，还会将写命令入队到复制积压缓冲区里面(这个大小可以调的) 

31. 哨兵机制：如果主服务器挂了，我们可以将从服务器升级为主服务器，等到旧的主服务器(挂掉的那个)重连上来，会将它(挂掉的主服务器)变成从服务器。

32. 启动和初始化sentinel：sentinel本质上是一个特殊的redis服务器，初始化时，sentinel不读取RDB,AOF文件，启动时，会将普通的Redis服务器的代码替换成Sentinel专用代码，接着，初始化Sentinel的状态，并根据给定的配置文件初始化Sentinel监视的主服务器列表，最后，Sentinel会创建两个连向主服务器的网络连接：命令连接，订阅连接

33. 获取和更新信息：Sentinel通过主服务器发送INFO命令来获得主服务器属下所有从服务器的地址信息，并为这些从服务器创建相应的实例结构，和命令连接，订阅连接。Sentinel通过命令连接以2秒一次的频率向所有主从服务器hello频道发送命令，并通过订阅连接接收hello频道的信息。

34. 判断主服务器是否下线：sentinel会**每秒一次**向所有主从服务器和其他sentinel发送**ping命令，**如果一个主服务器在down-after-milliseconds毫秒内连续向Sentinel发送**无效回复**，那么当前Sentinel就会主观认为该主服务器已经下线了（主观下线），同时它会向同样监视该主服务器的**Sentinel询问**，看它们是否也认为该主服务器是否下线，如果**足够多**的Sentinel认为该主服务器是下线的，那么就判定该主服务为**客观下线**，并对主服务器执行故障转移操作

35. 当判断一个主服务器客观下线后，会以**先到先得**的方式选出一个领头的sentinel，此sentinel会执行故障转移操作：1. 在已下线主服务器属下的从服务器中，挑选一个转换为主服务器 2. 让已下线主服务器属下的所有从服务器改为复制新的主服务器 3. 已下线的主服务器重新连接时，让他成为新的主服务器的从服务器 

36. 数据丢失：1.有部分数据没有复制到从服务器，主服务器就宕机了 2. 当master脱离正常网络，与slave断开连接，但master并没有宕机，此时sentinel 认为master宕机了，然后开始选举新的master，这个时候，集群中就会有两个master，就是所谓的脑裂。此时虽然某个slave转换成了master，但可能client还没有来得及切换到新的master，还在继续向旧的master写数据，就会丢失数据了。（因为旧master再次连接的时候，会被作为一个slave挂到新的master上去，自己的数据会被清空，重新从新的master复制数据。）min-slaves-to-write 1  min-slaves-max-lag 10 这两条命令减少数据丢失

37. 缓存雪崩（请求全部走数据库）：1. 对缓存数据设置**相同的过期时间**，导致某段时间内缓存失效，请求全部走数据库。解决：在缓存的时候给过期时间加上一个**随机值**，这样就会大幅度的减少缓存在同一时间过期 2. Redis挂掉了，请求全部走数据库。 解决：事发前：实现Redis的高可用**(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生  事发时：万一Redis真的挂了，我们可以设置**本地缓存(ehcache)+限流(hystrix)**，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)  事发后：**redis持久化**，重启后自动加载持久化数据，快速恢复缓存。

38. 缓存穿透：缓存穿透是指查询一个数据库**一定不存在的数据**。由于缓存不命中，并且出于容错考虑，如果从数据库查不到数据则不写入缓存，这将导致这个不存在的数据**每次请求都要到数据库去查询**，失去了缓存的意义。解决：1. 我们可以使用**布隆过滤器**(BloomFilter)（布隆过滤器判断数据库中没有这个数据，则直接返回null，而不是去数据库查询）或者压缩filter提前拦截，不合法就不让这个请求到数据库层！ 2. 当我们从数据库找不到的时候，我们也将这个**空对象设置到缓存**里边去。下次再请求的时候，就可以从缓存里边获取了，这种情况我们一般会将空对象设置一个较短的过期时间

39. 布隆过滤器：一种专门用来解决**去重**（用set去重内存消耗太大）问题的高级数据结构（并不是完全精确），当布隆过滤器说某个值**存在**时，这个值可能不存在；当它说**不存在**时，那么一定不存在。（redis4.0的server内置了布隆过滤器）  **缺点**：不准确，删除困难（不能简单的置为0，会妨碍其他值1）。

40. 原理：布隆过滤器本质上由长度为 m 的**位（bit）数组**（仅包含 0 或 1 位值的列表）组成，最初所有的值均设置为0，当我们向布隆过滤器添加数据时，会使用 多个 hash 函数对 key 进行运算，然后对位数组长度进行取模运算得到一个位置，每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为 1。向布隆过滤器查询时，与添加操作相同得到多个不同位置，查看对应的位置 是否都为 1，只要有一个位为0，那么说明布隆过滤器中这个key不存在。如果都为1，并不是一定存在，可能是由于其他key存在导致的。

41. 使用：1. 不要让实际元素数量远大于初始化数量 2. 当实际元素数量超过初始化数量时，应该对布隆过滤器**进行重建**，重新分配一个 size 更大的过滤器，再将所有的历史元素批量添加。

42. 缓存击穿：**某个缓存过期后**，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。  解决：对关键代码（从数据库读取数据）**加入双重校验锁**，每一刻都只有一个线程能访问数据库，且获取锁之前和之后都会判断缓存中是否已经存在数据了，存在则直接从缓存中读取。 如果应用程序是集群架构，则采用**分布式锁**。

43. 缓存不一致：操作缓存一般是直接删除即使之失效，而不更新（因为如果多写少读时，每次写入都更新缓存没有必要，不如直接删除，等到写的时候才读取）

44. 读写一致（三种模式不存在最佳，根据业务场景选择）

    > 1. Cache Aside pattern（旁路缓存）：写：更新 DB，然后直接删除 cache（没必要每次都写入cache，只需要删除就ok了，因为可能更新了还没读又要更新，所以没必要每次都更新）    读：从 cache 中读取数据，读取到就直接返回，读取不到的话，就从 DB 中取数据返回，然后再把数据放到 cache 中。   适合读请求比较多的场景
    > 2. read/write throgh pattern（读写穿透）：写（Write Through）：先查 cache，cache 中不存在，直接更新 DB。 cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（**同步更新 cache 和 DB**）。    读(Read Through)： 从 cache 中读取数据，读取到就直接返回 。读取不到的话，先从 DB 加载，写入到 cache 后返回响应。   在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由**客户端**自己负责把数据写入 cache，而 Read Through Pattern 则是 **cache 服务**自己来写入缓存的，这对客户端是透明的（写是由cache更新db，读也是由cache更新db）
    > 3. write behind pattern（异步缓存写入）：Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是**改为异步批量的方式来更新 DB**。Write Behind Pattern 下 DB 的**写性能**非常高，尤其适合一些数据经常变化的业务场景比如说一篇文章的点赞数量、阅读数量。但是，这种模式同样也给 DB 和 Cache 一致性带来了新的考验，很多时候如果数据还没异步更新到 DB 的话，Cache 服务宕机就 gg 了

45. 先删除缓存再更新数据库可能出现的问题：A线程为更新线程，A线程先删除了缓存数据（1），还没等到更新数据库（1），B线程（读取线程）就读取了缓存，发现被删除，然后读取数据库，再写入缓存（1），这时，A线程成功写入数据库（2），最后数据库中的数据为2，而缓存中的数据为1，不一致（A写入数据库之前，B读取了旧值并更新了缓存）。解决方法：异步串行化：更新和读取数据时，把数据的hashcode路由到jvm中的某个队列（因为根据hashcode路由，所以可知一个数据一个队列，一个队列对应一个工作线程），然后逐个执行队列中的请求，这样就保证了更新全部完成之后才能读取，读取彻底完成之后，才能更新。可能导致的问题：读请求长时间阻塞（当前面有很多条写数据时），读请求并发量过高。（可以根据具体情况添加服务器，多台服务器处理写请求）

46. Redis集群（集群中的每一个 Redis 节点都**互相两两相连**，客户端任意直连到集群中的任意一台，就可以对其他 Redis 节点进行**读写的操作**，因为如果槽不属于自己管，那么就会使用一个特殊的 MOVED 命令来进行一个跳转，告诉客户端去连接这个节点以获取数据）：集群使用16384个哈希槽，数据库中的每个键都属于这 16384 个哈希槽的其中一个，集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和，**集群中的每个节点负责处理一部分哈希槽**，集群中的每个节点两两互相连接。 集群的作用：**数据分区**（提高了可以存储的容量和集群响应速度），**高可用**（集群支持自动故障转移，当某一节点发生故障，集群仍然可以提供服务）。

47. Redis集群最少台数：6台，3台master节点，每个master节点对应1台slave节点，如果1台master对应2台slave，则需要9台服务器。

48. 数据分区方案：1.哈希值%节点数（即服务器数），问题：当新增或删减节点时，节点数量发生变化，系统中所有的数据都需要 重新计算映射关系，引发大规模数据迁移。 2.一致性哈希分区：将整个哈希值空间组织成一个虚拟的圆环，范围(即圆的周长)是 [0 , 2^32-1]，对于每一个数据，根据 key 计算 hash 值，确数据在环上的位置，然后从此位置沿顺时针行走，找到的第一台服务器就是其应该映射到的服务器，将 增减节点的影响限制在相邻节点，当节点数量少时，对单个节点的影响可能很大，如去掉某个节点，可能此节点的数据都会转移到下一个节点  3. 带有虚拟节点的一致性哈希分区：redis使用的方案，在上个方案的基础上增加了虚拟节点的概念（槽），**每个实际节点包含一定数量的槽**，槽是数据管理和迁移的基本单位。槽 解耦了数据和实际节点 之间的关系，增加或删除节点对系统的影响很小，如删除某个节点，只需要把它的槽均匀地分配给其他节点便可。

49. 节点通信机制：每个节点，都提供两个TCP端口：普通端口（程序员指定的端口，用于client连接的端口），集群端口（普通端口+10000，**集群端口只用于节点之间的通信**，如搭建集群、增减节点、故障转移等操作时节点间的通信；不要使用客户端连接集群接口。为了保证集群可以正常工作，在配置防火墙时，要同时开启普通端口和集群端口）

50. Gossip协议：节点通信可以分为几种类型：单对单，广播，Gossip等。1.广播：是指向集群内所有节点发送消息，优点 是集群的收敛速度快(集群收敛是指集群内所有节点获得的集群信息是一致的)，缺点 是每条消息都要发送给所有节点，CPU、带宽等消耗较大。2.Gossip协议：每个节点都 **“随机” 的与部分节点通信** （并不是真正的随机，而是根据特定的规则选择通信的节点），经过一番杂乱无章的通信，每个节点的状态很快会达到一致。Gossip 协议的优点有：负载 (比广播) 低、去中心化、容错性高 (因为通信有冗余) 等；缺点 主要是集群的**收敛速度慢**

51. 消息类型：集群中的节点采用 **固定频率（每秒10次）** 的 定时任务 进行通信相关的工作。节点间发送的消息主要分为 5 种：meet 消息、ping 消息、pong 消息、fail 消息、publish 消息。

52. 数据结构：节点为了存储集群状态而提供的数据结构中，最关键的是 clusterNode 和 clusterState 结构：前者记录了**一个节点**的状态（如创建时间，节点id，端口，槽等），后者记录了**集群**作为一个整体的状态（**槽分布信息**，自身节点等）。

53. HyperLogLog（场景：统计一个页面每天有多少用户访问n）使用：如果我们用set存储的话，需要花费大量的内存，而用hll只需要花费不多于12KB的内存（16384*6/8/1024），用pfadd加入字符串，用pfcount获取n值

54. 引入：伯努利实验，每次出现反面就停止，记录这次从开始到出现反面抛的次数k，总共抛n次（出现了n次反面），取n个k中的最大值kmax，则n约等于2^kmax。优化：进行m轮的n次实验（总共最多进行了m*n*kmax次抛硬币），每次都找出一个kmax，取m个kmax的调和平均数，则n约等于2^kmax。（利用伯努利实验的改进版，我们可以根据k求出n，n即使我们要求的总共访问用户量）对应：我们可以根据存入的字符串的hash值从右边起首次出现的1（即硬币中的反面）右边的连续0的个数记为k，一共存入了n个字符串（即n个用户），得到n个k，取其中的kmax，那么2^kmax就约等于n。优化：分桶，每个桶中存储的都是kmax，我们求出16384个kmax的调和平均数即可用求出n

55. Hll原理：首先，redis里面有2^14=16384个桶，**每个桶可以存储6bit**（即每个桶最大值为2^6=64，字符串被存入时，会被hash成64位的值（相同字符串hash值相同），**前14位用来分桶**，每个桶中存储在同一个桶中的所有字符串（一个桶可能存放很多不同的字符串，因为数据是百万级别）的kmax，然后根据16384个kmax求出**调和平均数k**，即可用2^k求出n  https://juejin.im/post/5c7900bf518825407c7eafd0

56. Hll的存储结构：密集型存储结构：16384个桶，每个桶6bit，**即12KB**。稀疏存储结构（便于缩小内存空间）：当都是0时存储一个非0的计数值即可(01xxxxxx yyyyyyyy)，如初始化都是0时，用01111111 11111111（即2^14）表示，只需要2字节 [https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/Redis/redis-collection/Reids(4)%E2%80%94%E2%80%94%E7%A5%9E%E5%A5%87%E7%9A%84HyperLoglog%E8%A7%A3%E5%86%B3%E7%BB%9F%E8%AE%A1%E9%97%AE%E9%A2%98.md](https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/Redis/redis-collection/Reids(4)——神奇的HyperLoglog解决统计问题.md)

57. Redis分布式锁（分布式环境（即多台应用服务器）中的java代码如何加锁？适用于非集群redis环境）：1.在redis中设置**一个key**，只有获取到了key的应用服务器才能执行加锁代码块 2.（锁超时问题）setnx虽然是原子操作，但不支持设置操作时间，可以**用set原子**设置key和它的过期时间 3.（del导致误删除问题，即删除其他线程获取的锁）可以把本线程的**id当作key的value**，只有value相同，才能执行删除操作  4.（删除锁非原子操作i++问题）用**lua脚本**使之变为原子操作  5.（过期时间大于业务时间）设置一个**守护线程**，当业务线程还没完成但是却快过期时，守护线程会给key增加过期时间，当业务线程执行完毕时，会关闭守护线程 ：https://juejin.im/post/5b16148a518825136137c8db  https://juejin.im/post/5b737b9b518825613d3894f4  **redison**已经帮我们实现了reids的分布式锁，不用我们自己实现（用zookeeper实现分布式锁更好）

58. 集群redis分布式锁（redlock）：算法：1. 得到当前的时间，微秒单位  2. Client使用相同的key和随机数,按照顺序在每个Master实例中尝试获得锁。在获得锁的过程中，为每一个锁操作设置一个快速失败时间(如果想要获得一个10秒的锁， 那么每一个锁操作的失败时间设为5-50ms，确保client不会在已经宕机的server上浪费时间)。 3. 客户端计算出与master获得锁操作过程中消耗的时间，当且仅当Client获得锁消耗的时间小于锁的**存活时间**，并且在一半以上的master节点中获得锁。才认为client成功的获得了锁。 4. 如果已经获得了锁，Client执行任务的时间窗口是锁的**存活时间减去获得锁消耗的时间**。 5. 如果Client获得锁的数量不足一半以上，或获得锁的时间超时，那么认为**获得锁失败**。客户端需要立刻尝试在**所有的master节点中释放锁**， 即使在第二步中没有成功获得该Master节点中的锁，仍要进行释放操作。  失败重试：如果一个Client无法获得锁，它将在一个**随机延时后开始重试**。使用随机延时的目的是为了与其他申请同一个锁的Client错开申请时间，减少脑裂(split brain)发生的可能性   崩溃和恢复：如果我们的节点没有持久化机制，client 从 5 个 master 中的 3 个处获得了锁，然后其中一个重启了，这时注意整个环境中又出现了 3 个 master 可供另一个 client 申请同一把锁！ 违反了互斥性。如果我们开启了 AOF 持久化那么情况会稍微好转一些，因为 Redis 的过期机制是语义层面实现的，所以在 server 挂了的时候时间依旧在流逝，重启之后锁状态不会受到污染。但是考虑断电之后呢，AOF部分命令没来得及刷回磁盘直接丢失了，除非我们配置刷回策略为 fsnyc = always，但这会损伤性能。解决这个问题的方法是，当一个节点重启之后，**我们规定在 max TTL 期间它是不可用的**，这样它就不会干扰原本已经申请到的锁，等到它 crash 前的那部分锁都过期了，环境不存在历史锁了，那么再把这个节点加进来正常工作

59. 发布订阅：发布者向频道发布信息，订阅了此频道的所有消费者都会自动接收到此条信息。模式订阅：h?llo，可以订阅hello，hallo等频道。Hell*，可以订阅hellooo，helllll等频道

60. 发布订阅原理（pubsub）：服务器维护了一个频道字典，字典的key为频道，value为订阅了此频道的所有client组成的链表。订阅就是向链表中加入客户端，发布就是遍历此频道下的链表并发送消息。服务器维护了一个模式链表，新增一个模式就把此模式加入链表，而每个模式又有一个客户端链表，发布时，服务器先发送信息给此频道下面的所有客户端，然后遍历模式链表，只要**模式与此频道匹配**，就把信息发送给此模式下的所有客户端。 问题：1.如果在某个客户端宕机时发布信息，那么此客户端就**接受不到此条信息**了，且发布信息的服务器也不知道 2.消息**不能持久化**，redis重启后所有消息都会被丢失

61. 持久化的发布订阅系统（Stream，redis5.0）：每个stream有一个key（首次添加消息时自动创建），对应一个消息队列，消息队列中存储多个消息，每个消息包括消息id和消息内容，消息id为‘整数-整数’形式，前一个整数为毫秒数，后整数为此消息为此毫秒数内生成第几个消息，消息内容为普通键值对。消费者组可以独立消费信息，也可以多个消费者同时加入一个消费者组进行组内消费，在消费者组中，多个消费者只有一个消费者能消费到某条信息，确保消息的唯一性。消费者组有一个last_delivered_id，用来表示消费者组消费在Stream上消费位置的游标信息。每个消费者有一个pending_ids，用来表示已经被客户端获取，但是还没有ack的消息，用来确保消费者宕机后还能继续消费宕机其间的消息（消费者消费完后会发送ack给服务端）。

62. Redis使用场景：1.显示最新项目列表（如微博显示最新评论，每次有评论就加入到redis种的list）  2.排行榜（用排序set） 3.利用hll统计（pfadd增加，scard统计命令）多少用户访问了某个资源 4.利用布隆过滤器去重（如抖音的推荐视频要去重） 5.计数（INCRBY原子递增操作） 6.分布式锁  7.频率限制，限制用户5秒内只能访问某接口2次（使用lua脚本和incr计数操作）Redis存储数据：最多能存放2.5亿个key，一个string类型的value最多512M，list/set/hashmap/sortedset元素个数最多为2^32-1。

63. redis大key问题：1. **什么是大key**：a. 单个简单的key存储的value很大，b. hash/set/zset/list中存储过多的元素。   2. **产生的问题**：a.内存使用不均匀，如集群中只有有bigkey的节点占用内存多QPS高。 b. 超时阻塞。（因为redis是单线程，当hash/set等元素超过100万时，需要1m时间）。c. 网络拥塞，如一个bigkey占用1m的空间，访问1000次，将造成1000M的流量。 3.**解决办法**：a. 对于单个key的value很大：可以将对象拆分成几个key-value，使用multiGet获取值，这样分拆的意义在于分拆单次操作的压力，将操作压力平摊到多个redis实例中，降低对单个redis的IO影响。b. hash/list等存储过多数据：可以对存储元素按一定规则进行分类，分散存储到多个redis实例中。或者再次精简需要存储的数据，比如榜单只存储前面后者后面的几百条，而不是全部。c. hash/list等大key的删除/过期：4.0之前可以分批删除集合中的数据  4.0之后引入了lazyfree机制，使用unlink命令可将删除操作放到后台，让子线程执行，避免主线程阻塞。    4.**bigkey的发现**：a. 执行bgsave命令，对生成的rdb文件使用redis-rdb-tools分析  b. 使用redis-cli的--bigkey命令    